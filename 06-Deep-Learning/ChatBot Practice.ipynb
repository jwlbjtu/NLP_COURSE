{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('train_qa.txt', 'rb') as f:\n",
    "    train_data = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('test_qa.txt', 'rb') as f:\n",
    "    test_data = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['Mary',\n",
       "  'moved',\n",
       "  'to',\n",
       "  'the',\n",
       "  'bathroom',\n",
       "  '.',\n",
       "  'Sandra',\n",
       "  'journeyed',\n",
       "  'to',\n",
       "  'the',\n",
       "  'bedroom',\n",
       "  '.'],\n",
       " ['Is', 'Sandra', 'in', 'the', 'hallway', '?'],\n",
       " 'no')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = train_data + test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11000"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = set()\n",
    "\n",
    "for story, question, answer in all_data:\n",
    "    vocab = vocab.union(set(story))\n",
    "    vocab = vocab.union(set(question))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab.add('no')\n",
    "vocab.add('yes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'.',\n",
       " '?',\n",
       " 'Daniel',\n",
       " 'Is',\n",
       " 'John',\n",
       " 'Mary',\n",
       " 'Sandra',\n",
       " 'apple',\n",
       " 'back',\n",
       " 'bathroom',\n",
       " 'bedroom',\n",
       " 'discarded',\n",
       " 'down',\n",
       " 'dropped',\n",
       " 'football',\n",
       " 'garden',\n",
       " 'got',\n",
       " 'grabbed',\n",
       " 'hallway',\n",
       " 'in',\n",
       " 'journeyed',\n",
       " 'kitchen',\n",
       " 'left',\n",
       " 'milk',\n",
       " 'moved',\n",
       " 'no',\n",
       " 'office',\n",
       " 'picked',\n",
       " 'put',\n",
       " 'the',\n",
       " 'there',\n",
       " 'to',\n",
       " 'took',\n",
       " 'travelled',\n",
       " 'up',\n",
       " 'went',\n",
       " 'yes'}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_len = len(vocab) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_story_lens = [len(data[0]) for data in all_data]\n",
    "max_story_lens = max(all_story_lens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "156"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_story_lens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_question_lens = [len(data[1]) for data in all_data]\n",
    "max_question_lens = max(all_question_lens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_question_lens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.preprocessing.text import Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(filters = [])\n",
    "tokenizer.fit_on_texts(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'went': 1,\n",
       " 'daniel': 2,\n",
       " 'to': 3,\n",
       " 'up': 4,\n",
       " 'discarded': 5,\n",
       " 'john': 6,\n",
       " 'back': 7,\n",
       " 'office': 8,\n",
       " 'got': 9,\n",
       " 'picked': 10,\n",
       " 'football': 11,\n",
       " 'mary': 12,\n",
       " 'grabbed': 13,\n",
       " 'apple': 14,\n",
       " '.': 15,\n",
       " 'yes': 16,\n",
       " 'kitchen': 17,\n",
       " 'there': 18,\n",
       " 'milk': 19,\n",
       " 'hallway': 20,\n",
       " 'garden': 21,\n",
       " 'is': 22,\n",
       " 'no': 23,\n",
       " 'took': 24,\n",
       " 'dropped': 25,\n",
       " '?': 26,\n",
       " 'bedroom': 27,\n",
       " 'travelled': 28,\n",
       " 'down': 29,\n",
       " 'moved': 30,\n",
       " 'put': 31,\n",
       " 'bathroom': 32,\n",
       " 'in': 33,\n",
       " 'sandra': 34,\n",
       " 'left': 35,\n",
       " 'the': 36,\n",
       " 'journeyed': 37}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_story_text = []\n",
    "train_question_text = []\n",
    "train_answers_text = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "for story, question, answer in train_data:\n",
    "    train_story_text.append(story)\n",
    "    train_question_text.append(question)\n",
    "    train_answers_text.append(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_story_seq = tokenizer.texts_to_sequences(train_story_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_story_seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorize_stories(data, word_index = tokenizer.word_index, max_story_lens = max_story_lens, max_question_lens = max_question_lens):\n",
    "    # STORIES - X\n",
    "    X = []\n",
    "    # QUESTIONS - Xq\n",
    "    Xq = []\n",
    "    # Y CORRECT ANSWER (yes/no)\n",
    "    Y = []\n",
    "    \n",
    "    for story, query, answer in data:\n",
    "        x = [word_index[word.lower()] for word in story]\n",
    "        xq = [word_index[word.lower()] for word in query]\n",
    "        y = np.zeros(len(word_index) + 1)\n",
    "        y[word_index[answer]] = 1\n",
    "        \n",
    "        X.append(x)\n",
    "        Xq.append(xq)\n",
    "        Y.append(y)\n",
    "        \n",
    "    return (pad_sequences(X, maxlen = max_story_lens), pad_sequences(Xq, maxlen = max_question_lens), np.array(Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_train, queries_train, answers_train = vectorize_stories(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_test, queries_test, answers_test = vectorize_stories(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0,  0,  0, ..., 36, 27, 15],\n",
       "       [ 0,  0,  0, ..., 36, 21, 15],\n",
       "       [ 0,  0,  0, ..., 36, 21, 15],\n",
       "       ...,\n",
       "       [ 0,  0,  0, ..., 36, 14, 15],\n",
       "       [ 0,  0,  0, ..., 36, 21, 15],\n",
       "       [ 0,  0,  0, ..., 14, 18, 15]], dtype=int32)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answers_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0., 497.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0., 503.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(answers_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential, Model\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.layers import Input, Activation, Dense, Permute, Dropout, add, dot, concatenate, LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_sequence = Input((max_story_lens,))\n",
    "question = Input((max_question_lens,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = len(vocab) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# INPUT ENCODER M\n",
    "input_encoder_m = Sequential()\n",
    "input_encoder_m.add(Embedding(input_dim = vocab_size, output_dim = 64))\n",
    "input_encoder_m.add(Dropout(0.3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# INPUT ENCODER C\n",
    "input_encoder_c = Sequential()\n",
    "input_encoder_c.add(Embedding(input_dim = vocab_size, output_dim = max_question_lens))\n",
    "input_encoder_c.add(Dropout(0.3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# QUESTION ENCODER\n",
    "question_encoder = Sequential()\n",
    "question_encoder.add(Embedding(input_dim = vocab_size, output_dim = 64, input_length = max_question_lens))\n",
    "question_encoder.add(Dropout(0.3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ENCODED\n",
    "input_encoded_m = input_encoder_m(input_sequence)\n",
    "input_encoded_c = input_encoder_c(input_sequence)\n",
    "question_encoded = question_encoder(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "match = dot([input_encoded_m, question_encoded], axes = (2, 2))\n",
    "match = Activation('softmax')(match)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = add([match, input_encoded_c])\n",
    "response = Permute((2, 1))(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "answer = concatenate([response, question_encoded])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'concatenate_1/concat:0' shape=(?, 6, 220) dtype=float32>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "answer = LSTM(32)(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "answer = Dropout(0.5)(answer)\n",
    "answer = Dense(vocab_size)(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "answer = Activation('softmax')(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model([input_sequence, question], answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer = 'rmsprop', loss = 'categorical_crossentropy', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 156)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            (None, 6)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "sequential_1 (Sequential)       multiple             2432        input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "sequential_3 (Sequential)       (None, 6, 64)        2432        input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dot_1 (Dot)                     (None, 156, 6)       0           sequential_1[1][0]               \n",
      "                                                                 sequential_3[1][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 156, 6)       0           dot_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "sequential_2 (Sequential)       multiple             228         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 156, 6)       0           activation_1[0][0]               \n",
      "                                                                 sequential_2[1][0]               \n",
      "__________________________________________________________________________________________________\n",
      "permute_1 (Permute)             (None, 6, 156)       0           add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 6, 220)       0           permute_1[0][0]                  \n",
      "                                                                 sequential_3[1][0]               \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   (None, 32)           32384       concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)             (None, 32)           0           lstm_1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 38)           1254        dropout_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 38)           0           dense_1[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 38,730\n",
      "Trainable params: 38,730\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 10000 samples, validate on 1000 samples\n",
      "Epoch 1/100\n",
      "10000/10000 [==============================] - 12s 1ms/step - loss: 0.9661 - acc: 0.4916 - val_loss: 0.6944 - val_acc: 0.4860\n",
      "Epoch 2/100\n",
      "10000/10000 [==============================] - 10s 1ms/step - loss: 0.7043 - acc: 0.5056 - val_loss: 0.6979 - val_acc: 0.5030\n",
      "Epoch 3/100\n",
      "10000/10000 [==============================] - 10s 1ms/step - loss: 0.6959 - acc: 0.5038 - val_loss: 0.6935 - val_acc: 0.4970\n",
      "Epoch 4/100\n",
      "10000/10000 [==============================] - 11s 1ms/step - loss: 0.6945 - acc: 0.5089 - val_loss: 0.6932 - val_acc: 0.5030\n",
      "Epoch 5/100\n",
      "10000/10000 [==============================] - 11s 1ms/step - loss: 0.6948 - acc: 0.4965 - val_loss: 0.6933 - val_acc: 0.5030\n",
      "Epoch 6/100\n",
      "10000/10000 [==============================] - 11s 1ms/step - loss: 0.6950 - acc: 0.4933 - val_loss: 0.6937 - val_acc: 0.4970\n",
      "Epoch 7/100\n",
      "10000/10000 [==============================] - 11s 1ms/step - loss: 0.6947 - acc: 0.4958 - val_loss: 0.6935 - val_acc: 0.4970\n",
      "Epoch 8/100\n",
      "10000/10000 [==============================] - 10s 1ms/step - loss: 0.6953 - acc: 0.4965 - val_loss: 0.6936 - val_acc: 0.5030\n",
      "Epoch 9/100\n",
      "10000/10000 [==============================] - 10s 1ms/step - loss: 0.6942 - acc: 0.5058 - val_loss: 0.6933 - val_acc: 0.4970\n",
      "Epoch 10/100\n",
      "10000/10000 [==============================] - 10s 994us/step - loss: 0.6945 - acc: 0.5011 - val_loss: 0.6940 - val_acc: 0.4970\n",
      "Epoch 11/100\n",
      "10000/10000 [==============================] - 10s 996us/step - loss: 0.6943 - acc: 0.5034 - val_loss: 0.6932 - val_acc: 0.4970\n",
      "Epoch 12/100\n",
      "10000/10000 [==============================] - 10s 990us/step - loss: 0.6944 - acc: 0.5047 - val_loss: 0.6939 - val_acc: 0.5030\n",
      "Epoch 13/100\n",
      "10000/10000 [==============================] - 10s 989us/step - loss: 0.6945 - acc: 0.4987 - val_loss: 0.6932 - val_acc: 0.5030\n",
      "Epoch 14/100\n",
      "10000/10000 [==============================] - 10s 993us/step - loss: 0.6941 - acc: 0.5010 - val_loss: 0.6930 - val_acc: 0.5150\n",
      "Epoch 15/100\n",
      "10000/10000 [==============================] - 10s 994us/step - loss: 0.6931 - acc: 0.5123 - val_loss: 0.6913 - val_acc: 0.5410\n",
      "Epoch 16/100\n",
      "10000/10000 [==============================] - 10s 1ms/step - loss: 0.6845 - acc: 0.5501 - val_loss: 0.6704 - val_acc: 0.6500\n",
      "Epoch 17/100\n",
      "10000/10000 [==============================] - 10s 1ms/step - loss: 0.6244 - acc: 0.6678 - val_loss: 0.5533 - val_acc: 0.7340\n",
      "Epoch 18/100\n",
      "10000/10000 [==============================] - 10s 997us/step - loss: 0.5038 - acc: 0.7743 - val_loss: 0.4522 - val_acc: 0.8180\n",
      "Epoch 19/100\n",
      "10000/10000 [==============================] - 10s 995us/step - loss: 0.4371 - acc: 0.8155 - val_loss: 0.4227 - val_acc: 0.8220\n",
      "Epoch 20/100\n",
      "10000/10000 [==============================] - 10s 998us/step - loss: 0.4053 - acc: 0.8316 - val_loss: 0.3987 - val_acc: 0.8280\n",
      "Epoch 21/100\n",
      "10000/10000 [==============================] - 10s 1ms/step - loss: 0.3764 - acc: 0.8441 - val_loss: 0.3816 - val_acc: 0.8420\n",
      "Epoch 22/100\n",
      "10000/10000 [==============================] - 10s 1ms/step - loss: 0.3622 - acc: 0.8492 - val_loss: 0.3793 - val_acc: 0.8210\n",
      "Epoch 23/100\n",
      "10000/10000 [==============================] - 10s 1000us/step - loss: 0.3544 - acc: 0.8503 - val_loss: 0.3743 - val_acc: 0.8450\n",
      "Epoch 24/100\n",
      "10000/10000 [==============================] - 10s 999us/step - loss: 0.3408 - acc: 0.8560 - val_loss: 0.3686 - val_acc: 0.8310\n",
      "Epoch 25/100\n",
      "10000/10000 [==============================] - 10s 998us/step - loss: 0.3280 - acc: 0.8580 - val_loss: 0.3725 - val_acc: 0.8380\n",
      "Epoch 26/100\n",
      "10000/10000 [==============================] - 10s 1ms/step - loss: 0.3292 - acc: 0.8561 - val_loss: 0.3502 - val_acc: 0.8400\n",
      "Epoch 27/100\n",
      "10000/10000 [==============================] - 10s 1ms/step - loss: 0.3253 - acc: 0.8612 - val_loss: 0.3481 - val_acc: 0.8340\n",
      "Epoch 28/100\n",
      "10000/10000 [==============================] - 10s 1ms/step - loss: 0.3209 - acc: 0.8582 - val_loss: 0.3465 - val_acc: 0.8290\n",
      "Epoch 29/100\n",
      "10000/10000 [==============================] - 10s 1ms/step - loss: 0.3172 - acc: 0.8602 - val_loss: 0.3493 - val_acc: 0.8270\n",
      "Epoch 30/100\n",
      "10000/10000 [==============================] - 10s 1ms/step - loss: 0.3133 - acc: 0.8624 - val_loss: 0.3378 - val_acc: 0.8390\n",
      "Epoch 31/100\n",
      "10000/10000 [==============================] - 10s 1ms/step - loss: 0.3136 - acc: 0.8600 - val_loss: 0.3396 - val_acc: 0.8490\n",
      "Epoch 32/100\n",
      "10000/10000 [==============================] - 10s 1ms/step - loss: 0.3097 - acc: 0.8658 - val_loss: 0.3383 - val_acc: 0.8340\n",
      "Epoch 33/100\n",
      "10000/10000 [==============================] - 10s 1000us/step - loss: 0.3032 - acc: 0.8680 - val_loss: 0.3542 - val_acc: 0.8290\n",
      "Epoch 34/100\n",
      "10000/10000 [==============================] - 10s 1ms/step - loss: 0.3072 - acc: 0.8615 - val_loss: 0.3526 - val_acc: 0.8440\n",
      "Epoch 35/100\n",
      "10000/10000 [==============================] - 10s 1ms/step - loss: 0.3066 - acc: 0.8669 - val_loss: 0.3487 - val_acc: 0.8410\n",
      "Epoch 36/100\n",
      "10000/10000 [==============================] - 10s 1ms/step - loss: 0.3030 - acc: 0.8663 - val_loss: 0.3476 - val_acc: 0.8380\n",
      "Epoch 37/100\n",
      "10000/10000 [==============================] - 10s 1ms/step - loss: 0.3031 - acc: 0.8668 - val_loss: 0.3498 - val_acc: 0.8430\n",
      "Epoch 38/100\n",
      "10000/10000 [==============================] - 10s 1ms/step - loss: 0.3004 - acc: 0.8698 - val_loss: 0.3401 - val_acc: 0.8410\n",
      "Epoch 39/100\n",
      "10000/10000 [==============================] - 10s 1ms/step - loss: 0.2990 - acc: 0.8679 - val_loss: 0.3486 - val_acc: 0.8480\n",
      "Epoch 40/100\n",
      "10000/10000 [==============================] - 10s 1ms/step - loss: 0.3000 - acc: 0.8660 - val_loss: 0.3388 - val_acc: 0.8470\n",
      "Epoch 41/100\n",
      "10000/10000 [==============================] - 10s 1ms/step - loss: 0.2991 - acc: 0.8673 - val_loss: 0.3352 - val_acc: 0.8480\n",
      "Epoch 42/100\n",
      "10000/10000 [==============================] - 10s 1ms/step - loss: 0.2995 - acc: 0.8678 - val_loss: 0.3522 - val_acc: 0.8380\n",
      "Epoch 43/100\n",
      "10000/10000 [==============================] - 10s 1ms/step - loss: 0.2967 - acc: 0.8675 - val_loss: 0.3619 - val_acc: 0.8360\n",
      "Epoch 44/100\n",
      "10000/10000 [==============================] - 10s 1ms/step - loss: 0.2979 - acc: 0.8681 - val_loss: 0.3634 - val_acc: 0.8390\n",
      "Epoch 45/100\n",
      "10000/10000 [==============================] - 10s 1ms/step - loss: 0.2957 - acc: 0.8684 - val_loss: 0.3560 - val_acc: 0.8350\n",
      "Epoch 46/100\n",
      "10000/10000 [==============================] - 10s 1ms/step - loss: 0.2939 - acc: 0.8739 - val_loss: 0.3721 - val_acc: 0.8310\n",
      "Epoch 47/100\n",
      "10000/10000 [==============================] - 10s 1ms/step - loss: 0.2941 - acc: 0.8699 - val_loss: 0.3604 - val_acc: 0.8410\n",
      "Epoch 48/100\n",
      "10000/10000 [==============================] - 10s 1ms/step - loss: 0.2917 - acc: 0.8673 - val_loss: 0.3518 - val_acc: 0.8430\n",
      "Epoch 49/100\n",
      "10000/10000 [==============================] - 10s 1ms/step - loss: 0.2908 - acc: 0.8704 - val_loss: 0.3422 - val_acc: 0.8520\n",
      "Epoch 50/100\n",
      "10000/10000 [==============================] - 10s 1ms/step - loss: 0.2905 - acc: 0.8711 - val_loss: 0.3577 - val_acc: 0.8410\n",
      "Epoch 51/100\n",
      "10000/10000 [==============================] - 10s 1ms/step - loss: 0.2923 - acc: 0.8702 - val_loss: 0.3493 - val_acc: 0.8370\n",
      "Epoch 52/100\n",
      "10000/10000 [==============================] - 10s 1ms/step - loss: 0.2922 - acc: 0.8721 - val_loss: 0.3686 - val_acc: 0.8300\n",
      "Epoch 53/100\n",
      "10000/10000 [==============================] - 10s 1ms/step - loss: 0.2906 - acc: 0.8711 - val_loss: 0.3515 - val_acc: 0.8440\n",
      "Epoch 54/100\n",
      "10000/10000 [==============================] - 10s 1ms/step - loss: 0.2882 - acc: 0.8745 - val_loss: 0.3524 - val_acc: 0.8430\n",
      "Epoch 55/100\n",
      "10000/10000 [==============================] - 10s 1ms/step - loss: 0.2910 - acc: 0.8724 - val_loss: 0.3499 - val_acc: 0.8330\n",
      "Epoch 56/100\n",
      "10000/10000 [==============================] - 10s 1ms/step - loss: 0.2885 - acc: 0.8714 - val_loss: 0.3644 - val_acc: 0.8410\n",
      "Epoch 57/100\n",
      "10000/10000 [==============================] - 10s 1ms/step - loss: 0.2905 - acc: 0.8709 - val_loss: 0.3483 - val_acc: 0.8460\n",
      "Epoch 58/100\n",
      "10000/10000 [==============================] - 10s 1ms/step - loss: 0.2893 - acc: 0.8736 - val_loss: 0.3582 - val_acc: 0.8350\n",
      "Epoch 59/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 10s 1ms/step - loss: 0.2874 - acc: 0.8746 - val_loss: 0.3722 - val_acc: 0.8350\n",
      "Epoch 60/100\n",
      "10000/10000 [==============================] - 10s 1ms/step - loss: 0.2816 - acc: 0.8752 - val_loss: 0.3697 - val_acc: 0.8360\n",
      "Epoch 61/100\n",
      "10000/10000 [==============================] - 10s 1ms/step - loss: 0.2857 - acc: 0.8750 - val_loss: 0.3588 - val_acc: 0.8330\n",
      "Epoch 62/100\n",
      "10000/10000 [==============================] - 10s 1ms/step - loss: 0.2877 - acc: 0.8751 - val_loss: 0.3564 - val_acc: 0.8420\n",
      "Epoch 63/100\n",
      "10000/10000 [==============================] - 10s 1ms/step - loss: 0.2857 - acc: 0.8768 - val_loss: 0.3668 - val_acc: 0.8460\n",
      "Epoch 64/100\n",
      "10000/10000 [==============================] - 10s 1ms/step - loss: 0.2797 - acc: 0.8750 - val_loss: 0.3609 - val_acc: 0.8520\n",
      "Epoch 65/100\n",
      "10000/10000 [==============================] - 10s 1ms/step - loss: 0.2834 - acc: 0.8788 - val_loss: 0.3775 - val_acc: 0.8370\n",
      "Epoch 66/100\n",
      "10000/10000 [==============================] - 10s 1ms/step - loss: 0.2812 - acc: 0.8774 - val_loss: 0.3722 - val_acc: 0.8410\n",
      "Epoch 67/100\n",
      "10000/10000 [==============================] - 10s 1ms/step - loss: 0.2734 - acc: 0.8809 - val_loss: 0.3804 - val_acc: 0.8380\n",
      "Epoch 68/100\n",
      "10000/10000 [==============================] - 10s 1ms/step - loss: 0.2818 - acc: 0.8791 - val_loss: 0.3424 - val_acc: 0.8360\n",
      "Epoch 69/100\n",
      "10000/10000 [==============================] - 10s 1ms/step - loss: 0.2748 - acc: 0.8800 - val_loss: 0.3679 - val_acc: 0.8430\n",
      "Epoch 70/100\n",
      "10000/10000 [==============================] - 10s 1ms/step - loss: 0.2779 - acc: 0.8767 - val_loss: 0.3520 - val_acc: 0.8370\n",
      "Epoch 71/100\n",
      "10000/10000 [==============================] - 10s 1ms/step - loss: 0.2812 - acc: 0.8772 - val_loss: 0.3769 - val_acc: 0.8330\n",
      "Epoch 72/100\n",
      "10000/10000 [==============================] - 10s 1ms/step - loss: 0.2768 - acc: 0.8771 - val_loss: 0.3625 - val_acc: 0.8490\n",
      "Epoch 73/100\n",
      "10000/10000 [==============================] - 10s 1ms/step - loss: 0.2732 - acc: 0.8803 - val_loss: 0.3658 - val_acc: 0.8320\n",
      "Epoch 74/100\n",
      "10000/10000 [==============================] - 10s 1ms/step - loss: 0.2722 - acc: 0.8824 - val_loss: 0.3655 - val_acc: 0.8330\n",
      "Epoch 75/100\n",
      "10000/10000 [==============================] - 10s 1ms/step - loss: 0.2703 - acc: 0.8806 - val_loss: 0.3596 - val_acc: 0.8410\n",
      "Epoch 76/100\n",
      "10000/10000 [==============================] - 10s 1ms/step - loss: 0.2737 - acc: 0.8778 - val_loss: 0.4003 - val_acc: 0.8390\n",
      "Epoch 77/100\n",
      "10000/10000 [==============================] - 10s 1ms/step - loss: 0.2668 - acc: 0.8817 - val_loss: 0.4142 - val_acc: 0.8380\n",
      "Epoch 78/100\n",
      "10000/10000 [==============================] - 10s 1ms/step - loss: 0.2649 - acc: 0.8836 - val_loss: 0.3569 - val_acc: 0.8440\n",
      "Epoch 79/100\n",
      "10000/10000 [==============================] - 10s 1ms/step - loss: 0.2669 - acc: 0.8830 - val_loss: 0.3642 - val_acc: 0.8380\n",
      "Epoch 80/100\n",
      "10000/10000 [==============================] - 10s 1ms/step - loss: 0.2710 - acc: 0.8865 - val_loss: 0.3860 - val_acc: 0.8330\n",
      "Epoch 81/100\n",
      "10000/10000 [==============================] - 10s 1ms/step - loss: 0.2662 - acc: 0.8857 - val_loss: 0.3700 - val_acc: 0.8380\n",
      "Epoch 82/100\n",
      "10000/10000 [==============================] - 10s 1ms/step - loss: 0.2581 - acc: 0.8847 - val_loss: 0.3862 - val_acc: 0.8360\n",
      "Epoch 83/100\n",
      "10000/10000 [==============================] - 10s 1ms/step - loss: 0.2654 - acc: 0.8870 - val_loss: 0.3939 - val_acc: 0.8300\n",
      "Epoch 84/100\n",
      "10000/10000 [==============================] - 10s 1ms/step - loss: 0.2637 - acc: 0.8858 - val_loss: 0.4187 - val_acc: 0.8220\n",
      "Epoch 85/100\n",
      "10000/10000 [==============================] - 10s 1ms/step - loss: 0.2595 - acc: 0.8899 - val_loss: 0.4159 - val_acc: 0.8380\n",
      "Epoch 86/100\n",
      "10000/10000 [==============================] - 10s 1ms/step - loss: 0.2620 - acc: 0.8891 - val_loss: 0.3628 - val_acc: 0.8410\n",
      "Epoch 87/100\n",
      "10000/10000 [==============================] - 10s 1ms/step - loss: 0.2610 - acc: 0.8883 - val_loss: 0.3868 - val_acc: 0.8410\n",
      "Epoch 88/100\n",
      "10000/10000 [==============================] - 10s 1ms/step - loss: 0.2564 - acc: 0.8877 - val_loss: 0.3605 - val_acc: 0.8380\n",
      "Epoch 89/100\n",
      "10000/10000 [==============================] - 11s 1ms/step - loss: 0.2578 - acc: 0.8871 - val_loss: 0.3981 - val_acc: 0.8420\n",
      "Epoch 90/100\n",
      "10000/10000 [==============================] - 11s 1ms/step - loss: 0.2544 - acc: 0.8912 - val_loss: 0.3516 - val_acc: 0.8370\n",
      "Epoch 91/100\n",
      "10000/10000 [==============================] - 11s 1ms/step - loss: 0.2480 - acc: 0.8917 - val_loss: 0.3806 - val_acc: 0.8420\n",
      "Epoch 92/100\n",
      "10000/10000 [==============================] - 12s 1ms/step - loss: 0.2535 - acc: 0.8877 - val_loss: 0.3896 - val_acc: 0.8390\n",
      "Epoch 93/100\n",
      "10000/10000 [==============================] - 12s 1ms/step - loss: 0.2474 - acc: 0.8944 - val_loss: 0.3689 - val_acc: 0.8410\n",
      "Epoch 94/100\n",
      "10000/10000 [==============================] - 12s 1ms/step - loss: 0.2512 - acc: 0.8909 - val_loss: 0.3886 - val_acc: 0.8430\n",
      "Epoch 95/100\n",
      "10000/10000 [==============================] - 12s 1ms/step - loss: 0.2497 - acc: 0.8952 - val_loss: 0.3995 - val_acc: 0.8380\n",
      "Epoch 96/100\n",
      "10000/10000 [==============================] - 12s 1ms/step - loss: 0.2456 - acc: 0.8956 - val_loss: 0.3801 - val_acc: 0.8370\n",
      "Epoch 97/100\n",
      "10000/10000 [==============================] - 12s 1ms/step - loss: 0.2387 - acc: 0.8953 - val_loss: 0.4062 - val_acc: 0.8360\n",
      "Epoch 98/100\n",
      "10000/10000 [==============================] - 12s 1ms/step - loss: 0.2452 - acc: 0.8953 - val_loss: 0.4273 - val_acc: 0.8440\n",
      "Epoch 99/100\n",
      "10000/10000 [==============================] - 12s 1ms/step - loss: 0.2383 - acc: 0.8984 - val_loss: 0.5047 - val_acc: 0.8300\n",
      "Epoch 100/100\n",
      "10000/10000 [==============================] - 12s 1ms/step - loss: 0.2428 - acc: 0.8961 - val_loss: 0.3863 - val_acc: 0.8380\n"
     ]
    }
   ],
   "source": [
    "history = model.fit([input_train, queries_train], answers_train, batch_size = 32, epochs = 100, validation_data = ([input_test, queries_test], answers_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'chatbot_jwl_100_epochs.h5'\n",
    "model.save(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['val_loss', 'val_acc', 'loss', 'acc'])\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "print(history.history.keys())\n",
    "\n",
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['val_acc'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc = 'upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_results = model.predict(([input_test, queries_test]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['Mary',\n",
       "  'got',\n",
       "  'the',\n",
       "  'milk',\n",
       "  'there',\n",
       "  '.',\n",
       "  'John',\n",
       "  'moved',\n",
       "  'to',\n",
       "  'the',\n",
       "  'bedroom',\n",
       "  '.'],\n",
       " ['Is', 'John', 'in', 'the', 'kitchen', '?'],\n",
       " 'no')"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.33439702e-20, 1.61223867e-20, 1.44818710e-20, 1.40011757e-20,\n",
       "       1.66986973e-20, 1.10844634e-20, 1.13837000e-20, 1.25420533e-20,\n",
       "       1.16911026e-20, 1.36195159e-20, 1.62792990e-20, 1.22839940e-20,\n",
       "       1.66975502e-20, 1.73411275e-20, 1.18130415e-20, 1.46754006e-20,\n",
       "       5.50589732e-07, 1.44860150e-20, 1.12693746e-20, 1.51089369e-20,\n",
       "       1.63574223e-20, 1.49957037e-20, 1.35580379e-20, 9.99999404e-01,\n",
       "       1.43944080e-20, 1.59851474e-20, 1.70485882e-20, 1.53875498e-20,\n",
       "       1.25732382e-20, 1.42133088e-20, 1.56460954e-20, 1.10312718e-20,\n",
       "       1.42485415e-20, 1.36893125e-20, 1.77668557e-20, 1.54249280e-20,\n",
       "       1.60280122e-20, 1.43315633e-20], dtype=float32)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_results[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "valmax = np.argmax(predict_results[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, val in tokenizer.word_index.items():\n",
    "    if val == valmax:\n",
    "        k = key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'no'"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9999994"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_results[0][valmax]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_story = \"John left the kitchen . Sandra dropped the football in the garden .\"\n",
    "my_ques = \"Is the football in the garden ?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_data = [(my_story.split(), my_ques.split(), 'yes')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(['John',\n",
       "   'left',\n",
       "   'the',\n",
       "   'kitchen',\n",
       "   '.',\n",
       "   'Sandra',\n",
       "   'dropped',\n",
       "   'the',\n",
       "   'football',\n",
       "   'in',\n",
       "   'the',\n",
       "   'garden',\n",
       "   '.'],\n",
       "  ['Is', 'the', 'football', 'in', 'the', 'garden', '?'],\n",
       "  'yes')]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_story, my_ques, my_answer = vectorize_stories(my_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_result = model.predict([my_story, my_ques])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "valmax = np.argmax(my_result[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, val in tokenizer.word_index.items():\n",
    "    if val == valmax:\n",
    "        k = key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'yes'"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.94849336"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_result[0][valmax]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
